{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d502f1fb",
   "metadata": {},
   "source": [
    "# Exploring Neural Spiking Data in Response to Transcranial Focused Ultrasound\n",
    "\n",
    "**IMPORTANT NOTICE**: This notebook was AI-generated using dandi-notebook-gen and has not been fully verified. Please exercise caution when interpreting the code or results.\n",
    "\n",
    "This notebook explores Dandiset 001363: \"Neural Spiking Data in the Rat Somatosensory Cortex Using a Flexible Electrode Responding to Transcranial Focused Ultrasound\"\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "This Dandiset contains neural recordings from rats in response to transcranial focused ultrasound stimulation (tFUS) on the somatosensory cortex. The researchers used a 128-element array transducer and a chronically implanted ultraflexible nanoelectric thread electrode to study neural responses to different ultrasound parameters.\n",
    "\n",
    "The key experimental parameters varied in this study include:\n",
    "\n",
    "1. **In situ ultrasound pressure**: 100, 400, 700, 1000, and 1300 kPa\n",
    "2. **Duty cycle** (with constant pulse repetition frequency at 1500 Hz): 0.6%, 6%, 30%, 60%, and 90% \n",
    "3. **Pulse repetition frequency (PRF)** (with constant duty cycle of 30%): 30, 300, 1500, 3000, and 4500 Hz\n",
    "\n",
    "Each recording contains 505 trials with stimulation occurring every 2 seconds (with a 10% jitter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ff221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages - make sure these are installed in your environment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "import pynwb\n",
    "import os\n",
    "\n",
    "# Optional: Set seaborn style for better-looking plots\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55195136",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Dandiset\n",
    "\n",
    "First, let's use the DANDI API to get information about the Dandiset and list its assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "\n",
    "# Create a client\n",
    "client = DandiAPIClient()\n",
    "\n",
    "# Get the Dandiset\n",
    "dandiset = client.get_dandiset(\"001363\")\n",
    "assets = list(dandiset.get_assets())\n",
    "\n",
    "# Use raw metadata to avoid validation errors\n",
    "raw_metadata = dandiset.get_raw_metadata()\n",
    "\n",
    "# Display basic Dandiset information\n",
    "print(f\"Dandiset Name: {raw_metadata['name']}\")\n",
    "print(f\"Description: {raw_metadata['description'][:500]}...\")\n",
    "print(f\"Number of assets: {len(assets)}\")\n",
    "\n",
    "# Display some of the contributors\n",
    "print(\"\\nContributors:\")\n",
    "for contributor in raw_metadata.get('contributor', [])[:5]:\n",
    "    print(f\"- {contributor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38ae9b",
   "metadata": {},
   "source": [
    "## Exploring the Assets\n",
    "\n",
    "Let's examine the assets in this Dandiset to understand what's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the first 10 assets\n",
    "print(\"First 10 assets:\")\n",
    "for i, asset in enumerate(assets[:10]):\n",
    "    print(f\"{i+1}. {asset.path} (Size: {asset.size/1e6:.2f} MB)\")\n",
    "\n",
    "# Group assets by subject\n",
    "subjects = {}\n",
    "for asset in assets:\n",
    "    path_parts = asset.path.split('/')\n",
    "    if len(path_parts) > 0:\n",
    "        subject = path_parts[0]\n",
    "        if subject not in subjects:\n",
    "            subjects[subject] = []\n",
    "        subjects[subject].append(asset.path)\n",
    "\n",
    "# Display the number of recordings per subject\n",
    "print(\"\\nNumber of recordings per subject:\")\n",
    "for subject, paths in subjects.items():\n",
    "    print(f\"{subject}: {len(paths)} recordings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad65eadb",
   "metadata": {},
   "source": [
    "## Loading Data from an NWB File\n",
    "\n",
    "Now let's load an NWB file from the Dandiset. We'll use the `lindi` package which allows efficient access to remote NWB files without downloading the entire file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lindi\n",
    "\n",
    "# Select the first file from subject BH589\n",
    "asset_id = \"59d1acbb-5ad5-45f1-b211-c2e311801824\"  # First session from subject BH589\n",
    "\n",
    "# URL for loading the data through lindi\n",
    "lindi_url = f\"https://lindi.neurosift.org/dandi/dandisets/001363/assets/{asset_id}/nwb.lindi.json\"\n",
    "\n",
    "# Load the file\n",
    "f = lindi.LindiH5pyFile.from_lindi_file(lindi_url)\n",
    "nwb = pynwb.NWBHDF5IO(file=f, mode='r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58354ea0",
   "metadata": {},
   "source": [
    "## Examining NWB File Metadata\n",
    "\n",
    "Let's look at the metadata in the NWB file to understand the experiment and recordings better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display session information\n",
    "print(f\"Session description: {nwb.session_description}\")\n",
    "print(f\"Identifier: {nwb.identifier}\")\n",
    "print(f\"Session start time: {nwb.session_start_time}\")\n",
    "print(f\"Institution: {nwb.institution}\")\n",
    "\n",
    "# Display subject information\n",
    "print(\"\\nSubject Information:\")\n",
    "print(f\"Subject ID: {nwb.subject.subject_id}\")\n",
    "print(f\"Species: {nwb.subject.species}\")\n",
    "print(f\"Sex: {nwb.subject.sex}\")\n",
    "print(f\"Age: {nwb.subject.age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f73a36",
   "metadata": {},
   "source": [
    "## Exploring the Acquired Neural Data\n",
    "\n",
    "The dataset contains electrical recordings from a 32-channel ultraflexible nanoelectric thread electrode. Let's examine the structure of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the electrical series data\n",
    "electrical_series = nwb.acquisition[\"ElectricalSeries\"]\n",
    "\n",
    "# Display information about the data\n",
    "print(f\"Data shape: {electrical_series.data.shape}\")\n",
    "print(f\"Sampling rate: {electrical_series.rate} Hz\")\n",
    "print(f\"Starting time: {electrical_series.starting_time} seconds\")\n",
    "\n",
    "# Examine electrodes\n",
    "electrodes = nwb.electrodes\n",
    "print(f\"\\nNumber of electrodes: {len(electrodes.id[:])}\")\n",
    "print(f\"Electrode columns: {electrodes.colnames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bb791",
   "metadata": {},
   "source": [
    "## Examining Trial Structure\n",
    "\n",
    "Each recording contains multiple trials of tFUS stimulation. Let's examine the trial structure to understand the experimental design better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trial information\n",
    "trials = nwb.intervals[\"trials\"]\n",
    "trial_start_times = trials['start_time'][:]\n",
    "trial_stop_times = trials['stop_time'][:]\n",
    "\n",
    "print(f\"Number of trials: {len(trial_start_times)}\")\n",
    "\n",
    "# Calculate trial durations\n",
    "trial_durations = trial_stop_times - trial_start_times\n",
    "\n",
    "# Calculate inter-trial intervals\n",
    "inter_trial_intervals = np.diff(trial_start_times)\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nTrial duration (mean ± std): {np.mean(trial_durations):.4f} ± {np.std(trial_durations):.4f} seconds\")\n",
    "print(f\"Inter-trial interval (mean ± std): {np.mean(inter_trial_intervals):.4f} ± {np.std(inter_trial_intervals):.4f} seconds\")\n",
    "\n",
    "# Plot the histogram of inter-trial intervals\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(inter_trial_intervals, bins=30)\n",
    "plt.xlabel('Inter-trial Interval (seconds)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Inter-trial Intervals')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f7da8",
   "metadata": {},
   "source": [
    "## Visualizing Raw Neural Data\n",
    "\n",
    "Let's visualize the raw neural activity for a single trial to see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a trial to visualize (e.g., trial 5)\n",
    "trial_index = 5  # Using an earlier trial to potentially reduce data access time\n",
    "trial_start = trial_start_times[trial_index]\n",
    "trial_stop = trial_stop_times[trial_index]\n",
    "\n",
    "# Define a smaller window around the trial\n",
    "window_before = 0.2  # seconds before trial (reduced)\n",
    "window_after = 0.2   # seconds after trial (reduced)\n",
    "\n",
    "# Calculate indices\n",
    "start_idx = int((trial_start - window_before) * electrical_series.rate)\n",
    "stop_idx = int((trial_stop + window_after) * electrical_series.rate)\n",
    "\n",
    "# Check boundaries\n",
    "if start_idx < 0:\n",
    "    start_idx = 0\n",
    "if stop_idx >= electrical_series.data.shape[0]:\n",
    "    stop_idx = electrical_series.data.shape[0] - 1\n",
    "\n",
    "# Select a subset of channels to visualize\n",
    "channels_to_plot = [0, 5, 10, 15, 20]  # A few representative channels\n",
    "\n",
    "# Load the data for these channels only\n",
    "data_subset = electrical_series.data[start_idx:stop_idx, channels_to_plot]\n",
    "\n",
    "# Create time axis in seconds relative to trial start\n",
    "time_axis = np.arange(data_subset.shape[0]) / electrical_series.rate\n",
    "time_axis = time_axis - window_before\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each channel with an offset\n",
    "offsets = np.arange(len(channels_to_plot)) * 100  # Offset for visualization\n",
    "for i, ch_idx in enumerate(channels_to_plot):\n",
    "    plt.plot(time_axis, data_subset[:, i] + offsets[i], label=f'Channel {ch_idx}')\n",
    "\n",
    "# Add vertical lines for trial start and end\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='Trial Start')\n",
    "plt.axvline(x=trial_stop-trial_start, color='g', linestyle='--', label='Trial End')\n",
    "\n",
    "plt.xlabel('Time relative to trial start (s)')\n",
    "plt.ylabel('Amplitude (μV + offset)')\n",
    "plt.title(f'Raw Neural Activity During Trial {trial_index+1}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb931e5",
   "metadata": {},
   "source": [
    "## Frequency Analysis of Neural Activity\n",
    "\n",
    "Let's examine how the frequency content of the neural signal changes before, during, and after tFUS stimulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single channel for frequency analysis\n",
    "channel_to_analyze = 0\n",
    "\n",
    "# Get data for the selected channel\n",
    "channel_data = data_subset[:, channels_to_plot.index(channel_to_analyze)]\n",
    "\n",
    "# Define time windows\n",
    "before_stim = time_axis < 0  # Before stimulation\n",
    "during_stim = (time_axis >= 0) & (time_axis <= trial_stop - trial_start)  # During stimulation\n",
    "after_stim = time_axis > (trial_stop - trial_start)  # After stimulation\n",
    "\n",
    "# Calculate power spectra using Welch's method\n",
    "f_before, psd_before = signal.welch(channel_data[before_stim], electrical_series.rate, \n",
    "                                    nperseg=min(1024, sum(before_stim)))\n",
    "f_during, psd_during = signal.welch(channel_data[during_stim], electrical_series.rate, \n",
    "                                    nperseg=min(1024, sum(during_stim)))\n",
    "f_after, psd_after = signal.welch(channel_data[after_stim], electrical_series.rate, \n",
    "                                 nperseg=min(1024, sum(after_stim)))\n",
    "\n",
    "# Plot frequency content\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.semilogy(f_before, psd_before, label='Before stimulus', alpha=0.8)\n",
    "plt.semilogy(f_during, psd_during, label='During stimulus', alpha=0.8)\n",
    "plt.semilogy(f_after, psd_after, label='After stimulus', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power/Frequency (μV²/Hz)')\n",
    "plt.title(f'Frequency Content - Channel {channel_to_analyze}')\n",
    "plt.xlim(0, 500)  # Limit to 0-500 Hz\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b19731",
   "metadata": {},
   "source": [
    "## Filtering the Data into Different Frequency Bands\n",
    "\n",
    "Neural signals contain information at different frequency bands. Let's filter the data to isolate local field potentials (LFPs) and high-frequency spike activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a877d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filters to isolate different frequency components\n",
    "from scipy import signal\n",
    "\n",
    "# Get the data from a single channel for a single trial\n",
    "channel_data = data_subset[:, channels_to_plot.index(channel_to_analyze)]\n",
    "\n",
    "# 1. LFP band (1-30 Hz)\n",
    "b_lfp, a_lfp = signal.butter(4, [1, 30], 'bandpass', fs=electrical_series.rate)\n",
    "lfp_filtered = signal.filtfilt(b_lfp, a_lfp, channel_data)\n",
    "\n",
    "# 2. High gamma band (60-200 Hz)\n",
    "b_gamma, a_gamma = signal.butter(4, [60, 200], 'bandpass', fs=electrical_series.rate)\n",
    "gamma_filtered = signal.filtfilt(b_gamma, a_gamma, channel_data)\n",
    "\n",
    "# 3. Spike band (>300 Hz)\n",
    "b_spikes, a_spikes = signal.butter(4, 300, 'highpass', fs=electrical_series.rate)\n",
    "spike_filtered = signal.filtfilt(b_spikes, a_spikes, channel_data)\n",
    "\n",
    "# Plot the filtered signals\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Raw data\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(time_axis, channel_data)\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.axvline(x=trial_stop-trial_start, color='g', linestyle='--')\n",
    "plt.title(f'Raw signal - Channel {channel_to_analyze}')\n",
    "plt.ylabel('Amplitude (μV)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# LFP band\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(time_axis, lfp_filtered)\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.axvline(x=trial_stop-trial_start, color='g', linestyle='--')\n",
    "plt.title('LFP band (1-30 Hz)')\n",
    "plt.ylabel('Amplitude (μV)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gamma band\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(time_axis, gamma_filtered)\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.axvline(x=trial_stop-trial_start, color='g', linestyle='--')\n",
    "plt.title('High gamma band (60-200 Hz)')\n",
    "plt.ylabel('Amplitude (μV)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Spike band\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(time_axis, spike_filtered)\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.axvline(x=trial_stop-trial_start, color='g', linestyle='--')\n",
    "plt.title('Spike band (>300 Hz)')\n",
    "plt.xlabel('Time relative to trial start (s)')\n",
    "plt.ylabel('Amplitude (μV)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18056f8",
   "metadata": {},
   "source": [
    "## Time-Frequency Analysis\n",
    "\n",
    "Let's perform time-frequency analysis to visualize how the spectral content changes over time during the trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c853935",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create a spectrogram of the signal around a trial\n",
    "from scipy import signal\n",
    "\n",
    "# Use a shorter segment to reduce computation time\n",
    "trial_index = 5\n",
    "window_before = 0.3  # seconds (reduced)\n",
    "window_after = 0.5   # seconds (reduced)\n",
    "\n",
    "trial_start = trial_start_times[trial_index]\n",
    "trial_stop = trial_stop_times[trial_index]\n",
    "\n",
    "start_idx = int((trial_start - window_before) * electrical_series.rate)\n",
    "stop_idx = int((trial_start + window_after) * electrical_series.rate)\n",
    "\n",
    "# Check boundaries\n",
    "if start_idx < 0:\n",
    "    start_idx = 0\n",
    "if stop_idx >= electrical_series.data.shape[0]:\n",
    "    stop_idx = electrical_series.data.shape[0] - 1\n",
    "\n",
    "# Load data for a single channel\n",
    "channel_to_analyze = 0\n",
    "data = electrical_series.data[start_idx:stop_idx, channel_to_analyze]\n",
    "\n",
    "# Create time axis relative to trial start\n",
    "time_rel = np.arange(len(data)) / electrical_series.rate - window_before\n",
    "\n",
    "# Compute spectrogram\n",
    "f, t, Sxx = signal.spectrogram(data, fs=electrical_series.rate, \n",
    "                               nperseg=int(0.1 * electrical_series.rate),  # 100ms window \n",
    "                               noverlap=int(0.09 * electrical_series.rate))  # 90% overlap\n",
    "\n",
    "# Plot spectrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pcolormesh(t + time_rel[0], f, 10 * np.log10(Sxx + 1e-10), shading='gouraud', cmap='viridis')\n",
    "plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
    "\n",
    "# Add vertical lines for trial start and end\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='Trial Start')\n",
    "plt.axvline(x=trial_stop - trial_start, color='g', linestyle='--', label='Trial End')\n",
    "\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time relative to trial start (s)')\n",
    "plt.title(f'Spectrogram - Channel {channel_to_analyze}')\n",
    "plt.ylim(0, 500)  # Limit to 0-500 Hz\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f712f3b2",
   "metadata": {},
   "source": [
    "## Spike Detection\n",
    "\n",
    "Now let's detect spikes in the neural signal to analyze spiking activity in response to tFUS stimulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d732b3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def detect_spikes(data, threshold_factor=5.0, fs=24414.0625):\n",
    "    \"\"\"\n",
    "    Detect spikes in neural data using a threshold-crossing method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array\n",
    "        The neural data.\n",
    "    threshold_factor : float\n",
    "        Factor to multiply the standard deviation for threshold setting.\n",
    "    fs : float\n",
    "        Sampling rate in Hz.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    spike_times : array\n",
    "        Time points (in seconds) of detected spikes.\n",
    "    \"\"\"\n",
    "    # Filter data (300 Hz highpass) to isolate spikes\n",
    "    b, a = signal.butter(3, 300/(fs/2), 'highpass')\n",
    "    filtered = signal.filtfilt(b, a, data)\n",
    "    \n",
    "    # Compute threshold based on filtered data\n",
    "    threshold = threshold_factor * np.std(filtered)\n",
    "    \n",
    "    # Detect threshold crossings (negative-going)\n",
    "    spike_indices = np.where(filtered < -threshold)[0]\n",
    "    \n",
    "    # Ensure spikes are separated by at least 1 ms (refractory period)\n",
    "    if len(spike_indices) > 1:\n",
    "        spike_times = [spike_indices[0]]\n",
    "        for i in range(1, len(spike_indices)):\n",
    "            if spike_indices[i] > spike_indices[i-1] + int(0.001 * fs):  # 1ms refractory period\n",
    "                spike_times.append(spike_indices[i])\n",
    "        return np.array(spike_times) / fs  # Convert to seconds\n",
    "    return spike_indices / fs  # Convert to seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffecfd",
   "metadata": {},
   "source": [
    "Let's apply the spike detection to our data and visualize the results for one trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7788fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a shorter segment for spike detection visualization\n",
    "window_before = 0.2  # seconds\n",
    "window_after = 0.3   # seconds\n",
    "\n",
    "start_idx = int((trial_start - window_before) * electrical_series.rate)\n",
    "stop_idx = int((trial_start + window_after) * electrical_series.rate)\n",
    "\n",
    "# Check boundaries\n",
    "if start_idx < 0:\n",
    "    start_idx = 0\n",
    "if stop_idx >= electrical_series.data.shape[0]:\n",
    "    stop_idx = electrical_series.data.shape[0] - 1\n",
    "\n",
    "# Load data\n",
    "channel_to_analyze = 0\n",
    "data = electrical_series.data[start_idx:stop_idx, channel_to_analyze]\n",
    "time_rel = np.arange(len(data)) / electrical_series.rate - window_before\n",
    "\n",
    "# Detect spikes\n",
    "spike_times = detect_spikes(data, threshold_factor=5.0, fs=electrical_series.rate)\n",
    "spike_times_rel = spike_times - window_before  # Convert to time relative to trial start\n",
    "\n",
    "# Filter data for visualization\n",
    "b, a = signal.butter(3, 300/(electrical_series.rate/2), 'highpass')\n",
    "filtered = signal.filtfilt(b, a, data)\n",
    "\n",
    "# Plot raw and filtered data with detected spikes\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Raw data\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time_rel, data, label='Raw Data')\n",
    "if len(spike_times_rel) > 0:\n",
    "    # For each spike, find the nearest index in the time vector\n",
    "    spike_indices = [np.abs(time_rel - t).argmin() for t in spike_times_rel]\n",
    "    plt.scatter(spike_times_rel, data[spike_indices], color='red', s=50, label='Detected Spikes')\n",
    "plt.axvline(x=0, color='k', linestyle='--', label='Stimulus Onset')\n",
    "plt.title(f'Spike Detection - Channel {channel_to_analyze}')\n",
    "plt.ylabel('Amplitude (μV)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Filtered data\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time_rel, filtered, label='Filtered Data (>300 Hz)')\n",
    "threshold = 5.0 * np.std(filtered)\n",
    "plt.axhline(y=-threshold, color='r', linestyle='--', label='Spike Threshold')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--')\n",
    "plt.axvline(x=0, color='k', linestyle='--', label='Stimulus Onset')\n",
    "plt.xlabel('Time relative to stimulus onset (s)')\n",
    "plt.ylabel('Amplitude (μV)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb737aa",
   "metadata": {},
   "source": [
    "## Analyzing Spike Rates Across Multiple Trials\n",
    "\n",
    "Let's analyze how spike rates change before, during, and after tFUS stimulation across multiple trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b350f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spike rates across a small number of trials\n",
    "num_trials_to_analyze = 5  # Reduced to speed up execution\n",
    "window_before = 0.2  # seconds (reduced)\n",
    "window_during = trial_durations[0]  # seconds - use the first trial's duration\n",
    "window_after = 0.2   # seconds (reduced)\n",
    "\n",
    "spike_counts_before = np.zeros(num_trials_to_analyze)\n",
    "spike_counts_during = np.zeros(num_trials_to_analyze)\n",
    "spike_counts_after = np.zeros(num_trials_to_analyze)\n",
    "\n",
    "for i in range(min(num_trials_to_analyze, len(trial_start_times))):\n",
    "    trial_start = trial_start_times[i]\n",
    "    trial_stop = trial_stop_times[i]\n",
    "    \n",
    "    # Calculate indices for before stimulation\n",
    "    before_start_idx = int((trial_start - window_before) * electrical_series.rate)\n",
    "    before_stop_idx = int(trial_start * electrical_series.rate)\n",
    "    \n",
    "    # Check boundaries\n",
    "    if before_start_idx < 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate indices for during stimulation\n",
    "    during_start_idx = int(trial_start * electrical_series.rate)\n",
    "    during_stop_idx = int(trial_stop * electrical_series.rate)\n",
    "    \n",
    "    # Calculate indices for after stimulation\n",
    "    after_start_idx = int(trial_stop * electrical_series.rate)\n",
    "    after_stop_idx = int((trial_stop + window_after) * electrical_series.rate)\n",
    "    \n",
    "    if after_stop_idx >= electrical_series.data.shape[0]:\n",
    "        continue\n",
    "    \n",
    "    # Load data for each segment\n",
    "    before_data = electrical_series.data[before_start_idx:before_stop_idx, channel_to_analyze]\n",
    "    during_data = electrical_series.data[during_start_idx:during_stop_idx, channel_to_analyze]\n",
    "    after_data = electrical_series.data[after_start_idx:after_stop_idx, channel_to_analyze]\n",
    "    \n",
    "    # Detect spikes\n",
    "    before_spikes = detect_spikes(before_data, threshold_factor=5.0, fs=electrical_series.rate)\n",
    "    during_spikes = detect_spikes(during_data, threshold_factor=5.0, fs=electrical_series.rate)\n",
    "    after_spikes = detect_spikes(after_data, threshold_factor=5.0, fs=electrical_series.rate)\n",
    "    \n",
    "    # Count spikes\n",
    "    spike_counts_before[i] = len(before_spikes)\n",
    "    spike_counts_during[i] = len(during_spikes)\n",
    "    spike_counts_after[i] = len(after_spikes)\n",
    "\n",
    "# Convert to spike rates (spikes per second)\n",
    "spike_rates_before = spike_counts_before / window_before\n",
    "spike_rates_during = spike_counts_during / window_during\n",
    "spike_rates_after = spike_counts_after / window_after\n",
    "\n",
    "# Calculate means and standard errors\n",
    "mean_rate_before = np.mean(spike_rates_before)\n",
    "mean_rate_during = np.mean(spike_rates_during)\n",
    "mean_rate_after = np.mean(spike_rates_after)\n",
    "\n",
    "sem_before = np.std(spike_rates_before) / np.sqrt(num_trials_to_analyze)\n",
    "sem_during = np.std(spike_rates_during) / np.sqrt(num_trials_to_analyze)\n",
    "sem_after = np.std(spike_rates_after) / np.sqrt(num_trials_to_analyze)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar([0, 1, 2], [mean_rate_before, mean_rate_during, mean_rate_after], \n",
    "        yerr=[sem_before, sem_during, sem_after], capsize=10)\n",
    "plt.xticks([0, 1, 2], ['Before\\nStimulation', 'During\\nStimulation', 'After\\nStimulation'])\n",
    "plt.ylabel('Spike Rate (spikes/second)')\n",
    "plt.title(f'Average Spike Rates Relative to tFUS Stimulation (Channel {channel_to_analyze})')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee65ca",
   "metadata": {},
   "source": [
    "## Creating a PSTH (Peri-Stimulus Time Histogram)\n",
    "\n",
    "Let's create a peri-stimulus time histogram to visualize the timing of spikes relative to the stimulus onset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PSTH across a small number of trials\n",
    "num_trials_psth = 5  # Reduced for faster execution\n",
    "window_before = 0.3  # seconds (reduced)\n",
    "window_after = 0.5   # seconds (reduced)\n",
    "bin_size = 0.1       # 100 ms bins (increased bin size to reduce computation)\n",
    "\n",
    "# Create bins for histogram\n",
    "bins = np.arange(-window_before, window_after + bin_size, bin_size)\n",
    "psth_counts = np.zeros(len(bins) - 1)\n",
    "\n",
    "trials_included = 0\n",
    "for i in range(min(num_trials_psth, len(trial_start_times))):\n",
    "    trial_start = trial_start_times[i]\n",
    "    \n",
    "    # Calculate indices\n",
    "    start_idx = int((trial_start - window_before) * electrical_series.rate)\n",
    "    stop_idx = int((trial_start + window_after) * electrical_series.rate)\n",
    "    \n",
    "    # Check boundaries\n",
    "    if start_idx < 0 or stop_idx >= electrical_series.data.shape[0]:\n",
    "        continue\n",
    "    \n",
    "    # Load data\n",
    "    data = electrical_series.data[start_idx:stop_idx, channel_to_analyze]\n",
    "    \n",
    "    # Detect spikes\n",
    "    spike_times = detect_spikes(data, threshold_factor=5.0, fs=electrical_series.rate)\n",
    "    \n",
    "    # Convert to time relative to stimulus onset\n",
    "    spike_times_rel = spike_times - window_before\n",
    "    \n",
    "    # Add to histogram\n",
    "    hist, _ = np.histogram(spike_times_rel, bins=bins)\n",
    "    psth_counts += hist\n",
    "    trials_included += 1\n",
    "\n",
    "# Convert to spikes per second\n",
    "psth_rate = psth_counts / (bin_size * trials_included)\n",
    "\n",
    "# Plot PSTH\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(bins[:-1], psth_rate, width=bin_size, alpha=0.7)\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='Stimulus Onset')\n",
    "plt.axvline(x=trial_durations[0], color='g', linestyle='--', label='Stimulus Offset (approx)')\n",
    "\n",
    "plt.xlabel('Time relative to stimulus onset (s)')\n",
    "plt.ylabel('Firing Rate (spikes/second)')\n",
    "plt.title(f'Peri-Stimulus Time Histogram (PSTH) - Channel {channel_to_analyze}, {trials_included} Trials')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eda0be",
   "metadata": {},
   "source": [
    "## Comparing Different Files (tFUS Parameters)\n",
    "\n",
    "This dataset includes recordings with different tFUS parameters. Let's compare neuronal responses across two different conditions.\n",
    "\n",
    "**Note**: In this demonstration, we use a small subset of trials to keep computation time reasonable. For more thorough analysis, you might want to increase the number of trials analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c52d4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load a second file with different parameters\n",
    "asset_id2 = \"6b9aa3e6-2389-4f84-a2d0-a3201894ad3c\"  # Subject BH589, fifth session\n",
    "\n",
    "# URL for loading the data through lindi\n",
    "lindi_url2 = f\"https://lindi.neurosift.org/dandi/dandisets/001363/assets/{asset_id2}/nwb.lindi.json\"\n",
    "\n",
    "# Load the second file\n",
    "f2 = lindi.LindiH5pyFile.from_lindi_file(lindi_url2)\n",
    "nwb2 = pynwb.NWBHDF5IO(file=f2, mode='r').read()\n",
    "\n",
    "# Display basic info about both files\n",
    "print(\"File 1 identifier:\", nwb.identifier)\n",
    "print(\"File 2 identifier:\", nwb2.identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c369641",
   "metadata": {},
   "source": [
    "Let's compare the LFP (1-30 Hz) power between these two conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_data_and_calculate_lfp_power(nwb_file, trial_index=0, channel_idx=0, window_before=0.5, window_after=0.5):\n",
    "    \"\"\"\n",
    "    Get trial data from an NWB file and calculate LFP power.\n",
    "    \"\"\"\n",
    "    # Get trial times and electrical series\n",
    "    trials = nwb_file.intervals[\"trials\"]\n",
    "    electrical_series = nwb_file.acquisition[\"ElectricalSeries\"]\n",
    "    \n",
    "    trial_start = trials['start_time'][trial_index]\n",
    "    trial_stop = trials['stop_time'][trial_index]\n",
    "    \n",
    "    # Calculate indices\n",
    "    start_idx = int((trial_start - window_before) * electrical_series.rate)\n",
    "    stop_idx = int((trial_stop + window_after) * electrical_series.rate)\n",
    "    \n",
    "    # Check boundaries\n",
    "    if start_idx < 0:\n",
    "        start_idx = 0\n",
    "    if stop_idx >= electrical_series.data.shape[0]:\n",
    "        stop_idx = electrical_series.data.shape[0] - 1\n",
    "    \n",
    "    # Load data\n",
    "    data = electrical_series.data[start_idx:stop_idx, channel_idx]\n",
    "    \n",
    "    # Filter to LFP band (1-30 Hz)\n",
    "    b, a = signal.butter(4, [1, 30], 'bandpass', fs=electrical_series.rate)\n",
    "    lfp_filtered = signal.filtfilt(b, a, data)\n",
    "    \n",
    "    # Calculate power\n",
    "    lfp_power = np.mean(lfp_filtered**2)\n",
    "    \n",
    "    return lfp_power\n",
    "\n",
    "# Calculate LFP power for a few trials in both files\n",
    "num_trials = 3  # Reduced to avoid timeout issues\n",
    "channel = 0\n",
    "lfp_powers_file1 = []\n",
    "lfp_powers_file2 = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "    # File 1\n",
    "    power1 = get_trial_data_and_calculate_lfp_power(nwb, trial_index=i, channel_idx=channel)\n",
    "    lfp_powers_file1.append(power1)\n",
    "    \n",
    "    # File 2\n",
    "    power2 = get_trial_data_and_calculate_lfp_power(nwb2, trial_index=i, channel_idx=channel)\n",
    "    lfp_powers_file2.append(power2)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([lfp_powers_file1, lfp_powers_file2], labels=[nwb.identifier, nwb2.identifier])\n",
    "plt.ylabel('LFP Power (μV²)')\n",
    "plt.title(f'Comparison of LFP Power Between Two tFUS Conditions - Channel {channel}')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b1c3d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored neural spiking data in response to transcranial focused ultrasound stimulation from Dandiset 001363. We've:\n",
    "\n",
    "1. Loaded and examined the structure of NWB files containing neural recordings\n",
    "2. Visualized raw neural activity around stimulation trials\n",
    "3. Analyzed the frequency content of neural signals before, during, and after stimulation\n",
    "4. Detected spikes and calculated spike rates in response to stimulation\n",
    "5. Created a peri-stimulus time histogram (PSTH) to visualize spike timing relative to stimulation\n",
    "6. Compared neural responses between different tFUS stimulation parameters\n",
    "\n",
    "This analysis provides a starting point for more in-depth investigations of how transcranial focused ultrasound affects neural activity in the rat somatosensory cortex. Researchers interested in this dataset could:\n",
    "\n",
    "- Analyze changes in specific frequency bands (theta, beta, gamma) in response to stimulation\n",
    "- Compare responses across different ultrasound parameters (pressure, duty cycle, PRF)\n",
    "- Investigate latency of neural responses to stimulation\n",
    "- Apply more advanced spike sorting techniques to identify and analyze individual neurons\n",
    "- Examine spatial patterns of activation across different electrodes\n",
    "\n",
    "Remember that this notebook was AI-generated and should be used as a starting point for your own analysis, with appropriate verification of results."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
